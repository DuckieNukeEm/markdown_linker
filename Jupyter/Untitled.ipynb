{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b72514ca-49b8-4f0c-81b5-0cc997e02d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import logging\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2634e06d-929e-4553-ac84-3111dce09d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath('/home/asmodi/Code/git/markdown_linker/src/'))\n",
    "from Backlink import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb58ecf3-3855-4967-ae07-3985dbfca70d",
   "metadata": {},
   "source": [
    "## Sys Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1b4c371-bfb4-4a5e-9f9d-a7b1a8ff245b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__():\n",
    "    sys_dict = generate_sys_dict()\n",
    "    md_list = generate_link_list(sys_dict['SYSTEM_PATH'])\n",
    "    sys_dict = populate_markdown_dictionary(md_list, sys_dict)\n",
    "    sys_dict = markdown_crossrefrence(sys_dict)\n",
    "    return sys_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25010e29-0c62-4b30-8079-11c8e2158d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_dict  = __init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39a3b7f6-db72-480b-8d20-1f7c3460e6b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/asmodi/Code/git/markdown_linker/test/markdown/SlipBox/AI_Levels_20280826.md')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_dict['MARKDOWNS_DICT']['/SlipBox/AI_Levels_20280826.md']['PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f7122e3-cf73-4df5-a9a3-aa1b33d9c30c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PATH': PosixPath('/home/asmodi/Code/git/markdown_linker/test/markdown/SlipBox/AI_Levels_20280826.md'),\n",
       " 'REL_PATH': '/SlipBox/AI_Levels_20280826.md',\n",
       " 'BACKLINKS': [('Static Axioms and Dynamic Policies',\n",
       "   '/SlipBox/BetterThanHuman_or_BetterThanHumanAndMachine_20250826/Static_Axioms_and_Dynamic_Policies.md')],\n",
       " 'BACKLINKS_PATH': ['/SlipBox/BetterThanHuman_or_BetterThanHumanAndMachine_20250826/Static_Axioms_and_Dynamic_Policies.md'],\n",
       " 'LINKS': [],\n",
       " 'LINKS_PATH': [],\n",
       " 'NEED2UPDATE': False,\n",
       " 'ID': None,\n",
       " 'DESCRIPTION': '',\n",
       " 'TAGS': ['purpose', ' system applicaitons'],\n",
       " 'EDITOR': 'markdown',\n",
       " 'TITLE': 'AI Levels',\n",
       " 'DATECREATED': '2025-08-27T02:00:35.044Z',\n",
       " 'PUBLISHED': 'true',\n",
       " 'DATE': '2025-08-27T02:00:35.044Z'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_dict['MARKDOWNS_DICT']['/SlipBox/AI_Levels_20280826.md']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fb0a25-e9c8-4729-981c-2564722217e5",
   "metadata": {},
   "source": [
    "# Internal Logic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014710a3-d755-41f4-9141-1c6edd132189",
   "metadata": {},
   "source": [
    "# Loading Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23024b40-f224-49f5-8a1b-923b3df0d526",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_backlink_section(markdown_dict):\n",
    "    txt_list = []\n",
    "    for title, lnk in markdown_dict['BACKLINKS_PATH']:\n",
    "        txt_list.append(f'- [{title}]({lnk})')\n",
    "\n",
    "    txt = '\\n# Backlinks\\n\\n' + '\\n'.join(txt_list)\n",
    "    return(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "851fd16b-7a4f-4ade-a3cd-37628f182de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_markdown_file(markdown_dic, FixLists):\n",
    "    markdown_content = read_markdown_doc(markdown_dic['PATH'])\n",
    "\n",
    "    # step 1 fix backlinks\n",
    "    if markdown_dic['REL_PATH'] in FixLists.get('BACKLINKS',''):\n",
    "        split_md = split_on_backlinks_section(markdown_content)\n",
    "        split_md = split_md[0]\n",
    "        backlinks_section = generate_backlink_section(markdown_dic)\n",
    "        markdown_content = split_md + backlinks_section\n",
    "        FixLists['BACKLINKS'].remove(markdown_dic['REL_PATH'])\n",
    "    # step 2 - add anything else that needs to be fixed\n",
    "\n",
    "    # step 3 - save\n",
    "    write_markdown_doc(markdown_dic['PATH'], markdown_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0354b92c-6915-47b9-b4dc-3b73c73b1c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_markdowns(system_dic):\n",
    "    markdown_2_update = list(set(sum(system_dic.get('UPDATE', {}).values(), [])))\n",
    "    for md in markdown_2_update:\n",
    "        update_markdown_file(system_dic['MARKDOWNS_DICT'][md], system_dic['UPDATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fa44605e-3e06-4ccc-a6da-85030f085a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "MARKDOWN_FILE = read_markdown_doc(system_dict['MARKDOWNS_DICT']['/SlipBox/AI_Levels_20280826.md']['PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cc2992a3-a5bf-4f3c-83a0-6ee7385672e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'---\\ntitle: AI Levels\\ndescription: \\npublished: true\\ndate: 2025-08-27T02:00:35.044Z\\ntags: purpose, system applicaitons\\neditor: markdown\\ndateCreated: 2025-08-27T02:00:35.044Z\\n---\\n\\n# AI levels\\n\\n**Unique Id:** c2b858a4fcc1eb9d9e85490553e63c85 \\n#sysemApplication\\n#Purpose\\n\\n----\\n\\nThere are at least three different levels to AI. Their is the backend level, which either allows for the use of \"code vibing\" or enhancment of the development space, then the front end, which is what a customer interacts with: Think the backstreet boys having the floating heads move and \"sync\" to the actual singers. Then there is the middle ground, is unclear to me what of that that is.\\n\\nIn each cases, the application, **end goal**, and money path is different.\\n\\n# '"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MARKDOWN_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "44854c58-a028-4a18-8e05-9d441ec6df94",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_dict['UPDATE']['BACKLINKS'] = system_dict['UPDATE']['backlinks'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "845814f0-1636-4234-ac8e-e2d410e39359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Backlinks\\n\\n- [Static Axioms and Dynamic Policies](/SlipBox/BetterThanHuman_or_BetterThanHumanAndMachine_20250826/Static_Axioms_and_Dynamic_Policies.md)'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_backlink_section(system_dict['MARKDOWNS_DICT']['/SlipBox/AI_Levels_20280826.md'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bda16387-e13f-4380-8173-b320764471ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_markdown_file(system_dict['MARKDOWNS_DICT']['/SlipBox/AI_Levels_20280826.md'],system_dict['UPDATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9c067614-1f41-4bc3-a6d5-be96129ec99a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'---\\ntitle: AI Levels\\ndescription: \\npublished: true\\ndate: 2025-08-27T02:00:35.044Z\\ntags: purpose, system applicaitons\\neditor: markdown\\ndateCreated: 2025-08-27T02:00:35.044Z\\n---\\n\\n# AI levels\\n\\n**Unique Id:** c2b858a4fcc1eb9d9e85490553e63c85 \\n#sysemApplication\\n#Purpose\\n\\n----\\n\\nThere are at least three different levels to AI. Their is the backend level, which either allows for the use of \"code vibing\" or enhancment of the development space, then the front end, which is what a customer interacts with: Think the backstreet boys having the floating heads move and \"sync\" to the actual singers. Then there is the middle ground, is unclear to me what of that that is.\\n\\nIn each cases, the application, **end goal**, and money path is different.\\n\\n# \\n# Backlinks\\n\\n- [Static Axioms and Dynamic Policies](/SlipBox/BetterThanHuman_or_BetterThanHumanAndMachine_20250826/Static_Axioms_and_Dynamic_Policies.md)'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_markdown_doc(system_dict['MARKDOWNS_DICT']['/SlipBox/AI_Levels_20280826.md']['PATH'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1a8b11-b39b-4596-a5ec-3d6e81da64c9",
   "metadata": {},
   "source": [
    "# Old Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076c5bc4-7d89-464e-b939-fb754d11aa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scan_documents(scan_path):\n",
    "    \"\"\"Scan all markdown files and build comprehensive link data\"\"\"\n",
    "    scan_path = Path(scan_path).resolve()\n",
    "    logging.info(f\"Scanning documents in {scan_path}\")\n",
    "    csv_path = scan_path / 'backlinks.csv'\n",
    "    # existing_data = load_csv_data(csv_path)\n",
    "    \n",
    "\n",
    "    markdown_header = {} # Map of file path to its header/title\n",
    "    links_data = []\n",
    "    backlinks_map = defaultdict(set)\n",
    "    md_files = list(scan_path.rglob('*.md'))\n",
    "    \n",
    "    logging.info(f\"Found {len(md_files)} markdown files\")\n",
    "    \n",
    "    for md_file in md_files:\n",
    "        content = read_markdown_doc(md_file)\n",
    "            \n",
    "        links_found = find_markdown_links(content)\n",
    "        if links_found:\n",
    "            logging.debug(f\"Found {len(links_found)} links in {md_file.name}\")\n",
    "        print(links_found)    \n",
    "        for link_text, target_file in links_found:\n",
    "            # Handle links relative to scan directory\n",
    "            if target_file.startswith('/'):\n",
    "                # Link is scan-relative (e.g., /TESTDIR/docs/file.md)\n",
    "                target_parts = Path(target_file).parts[1:]  # Remove leading '/'\n",
    "                if target_parts and target_parts[0].upper() == scan_path.name.upper():\n",
    "                    # Link points within scan structure - convert to absolute path\n",
    "                    rel_path = Path(*target_parts[1:]) if len(target_parts) > 1 else Path('.')\n",
    "                    target_path = (scan_path / rel_path).resolve()\n",
    "                    logging.debug(f\"Resolved scan-relative link {target_file} to {target_path}\")\n",
    "                else:\n",
    "                    # Link points outside scan structure\n",
    "                    target_path = Path(target_file)\n",
    "            else:\n",
    "                # Link is relative to current file location\n",
    "                target_path = (md_file.parent / target_file).resolve()\n",
    "            \n",
    "            # Determine status - check existence with absolute path\n",
    "            if target_path.exists():\n",
    "                if scan_path in target_path.parents or target_path == scan_path:\n",
    "                    status = 'Valid'\n",
    "                else:\n",
    "                    status = 'Outside Root'\n",
    "                    logging.warning(f\"Link outside scan path: {md_file.name} -> {target_file}\")\n",
    "            else:\n",
    "                status = 'Broken'\n",
    "                logging.error(f\"Broken link: {md_file.name} -> {target_file} (resolved to {target_path})\")\n",
    "            \n",
    "            # Convert to scan-relative paths for CSV\n",
    "            source_rel = get_scan_relative_path(md_file, scan_path)\n",
    "            target_rel = get_scan_relative_path(target_path, scan_path)\n",
    "            \n",
    "            # Get or find titles/headers\n",
    "            title_found = find_markdown_title(content)\n",
    "            if title_found:\n",
    "                logging.debug(f\"Found header in {md_file.name}: {title_found}\")\n",
    "            \n",
    "            markdown_header = add_headers_dict(markdown_header, md_file, title_found)\n",
    "\n",
    "            if markdown_header.get(target_path) is None and target_path.exists():\n",
    "                with open(target_path, 'r', encoding='utf-8') as tf:\n",
    "                    tcontent = tf.read()\n",
    "                ttitle_found = find_markdown_title(tcontent)\n",
    "\n",
    "                markdown_header = add_headers_dict(markdown_header, target_path, ttitle_found)\n",
    "\n",
    "            # Add original link\n",
    "            links_data.append({\n",
    "                'source_file': source_rel,\n",
    "                'source_title': markdown_header[md_file],\n",
    "                'target_file': target_rel,\n",
    "                'target_title': markdown_header[target_path],\n",
    "                'link_text': link_text,\n",
    "                'status': status,\n",
    "                'hierarchy_level': get_hierarchy_level(md_file, scan_path),\n",
    "                'link_type': 'original'\n",
    "            })\n",
    "            \n",
    "            # Add backlink entry regardless of validity\n",
    "            links_data.append({\n",
    "                'source_file': target_rel,\n",
    "                'source_title': markdown_header[target_path],\n",
    "                'target_file': source_rel,\n",
    "                'target_title': markdown_header[md_file],\n",
    "                'link_text': '',\n",
    "                'status': status,  # Use same status as original link\n",
    "                'hierarchy_level': get_hierarchy_level(target_path, scan_path),\n",
    "                'link_type': 'backlink'\n",
    "            })\n",
    "            \n",
    "            if status == 'Valid':\n",
    "                backlinks_map[target_rel].add((source_rel, markdown_header[md_file]))\n",
    "    \n",
    "    save_csv_data(csv_path, links_data)\n",
    "    return backlinks_map\n",
    "\n",
    "\n",
    "def add_backlinks(scan_path):\n",
    "    \"\"\"Add backlinks to markdown files\"\"\"\n",
    "    scan_path = Path(scan_path).resolve()\n",
    "    backlinks_map = scan_documents(scan_path)\n",
    "    \n",
    "    files_updated = 0\n",
    "    for target_file_rel, source_files_rel in backlinks_map.items():\n",
    "        # Convert scan-relative path back to absolute for file operations\n",
    "        if target_file_rel.startswith('/' + scan_path.name):\n",
    "            rel_part = target_file_rel[len('/' + scan_path.name):].lstrip('/')\n",
    "            target_path = scan_path / rel_part if rel_part else scan_path\n",
    "        else:\n",
    "            target_path = Path(target_file_rel)  # Outside scan path, use as-is\n",
    "            \n",
    "        logging.debug(f\"Processing backlinks for {target_path.name}\")\n",
    "        \n",
    "        with open(target_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        existing_backlinks = get_existing_backlinks(content)\n",
    "        \n",
    "        # Remove existing backlinks section\n",
    "        content = re.sub(r'\\n# Backlinks\\n.*?(?=\\n# |\\Z)', '', content, flags=re.DOTALL)\n",
    "        \n",
    "        # Build new backlinks section with only new links\n",
    "        new_backlinks = []\n",
    "        for source_file_rel in source_files_rel:\n",
    "            # Convert scan-relative path back to absolute for path calculations\n",
    "            if False:\n",
    "                print(source_file_rel)\n",
    "                if source_file_rel[0].startswith('/' + scan_path.name):\n",
    "                    rel_part = source_file_rel[0][len('/' + scan_path.name):].lstrip('/')\n",
    "                    print(rel_part)\n",
    "                    source_path = scan_path / rel_part if rel_part else scan_path\n",
    "                    print(rel_part, source_path)\n",
    "                else:\n",
    "                    source_path = Path(source_file_rel[0])  # Outside scan path, use as-is\n",
    "            #source_path = Path(source_file_rel[0])  # Outside scan path, use as-is\n",
    "            #rel_path = os.path.relpath(source_path, target_path.parent)\n",
    "            rel_path = source_file_rel[0]\n",
    "            if rel_path not in existing_backlinks:\n",
    "                #source_name = source_path.stem\n",
    "                new_backlinks.append(f'- [{source_file_rel[1]}]({rel_path})')\n",
    "            #print(source_path, source_path.stem, rel_path, existing_backlinks)\n",
    "        \n",
    "        if new_backlinks:\n",
    "            # Remove existing backlinks section\n",
    "            content = re.sub(r'\\n# Backlinks\\n.*?(?=\\n# |\\Z)', '', content, flags=re.DOTALL)\n",
    "        \n",
    "            logging.info(f\"Adding {len(new_backlinks)} backlinks to {target_path.name}\")\n",
    "            backlinks_section = '\\n# Backlinks\\n\\n' + '\\n'.join(new_backlinks) + '\\n'\n",
    "            \n",
    "            with open(target_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(content + backlinks_section)\n",
    "            files_updated += 1\n",
    "    \n",
    "    logging.info(f\"Updated {files_updated} files with backlinks\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='Generate backlinks for markdown files')\n",
    "    parser.add_argument('scan_path', nargs='?', help='Folder path to scan for markdown files')\n",
    "    parser.add_argument('--log-level', choices=['DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL'], \n",
    "                       default='INFO', help='Logging level')\n",
    "    parser.add_argument('--log-file', help='Log file path (optional)')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    setup_logging(args.log_level, args.log_file)\n",
    "    \n",
    "    # Use SCAN_PATH if defined, otherwise use command line arg or prompt\n",
    "    if SCAN_PATH:\n",
    "        scan_path = SCAN_PATH\n",
    "        logging.info(f\"Using hard-coded SCAN_PATH: {SCAN_PATH}\")\n",
    "    else:\n",
    "        scan_path = args.scan_path or input(\"Enter scan folder path: \").strip()\n",
    "    \n",
    "    try:\n",
    "        add_backlinks(scan_path)\n",
    "        logging.info(\"Backlinks processing completed successfully!\")\n",
    "        print(\"Backlinks added successfully! Check backlinks.csv for link analysis.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing backlinks: {e}\")\n",
    "        raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
